{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T12:04:57.838183Z",
     "start_time": "2026-01-30T12:04:53.668630300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Breaking-CAPTCHAS-Pytorch.py\n",
    "# PyTorch version of EE 467 Lab 2 CAPTCHA CNN\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "\n",
    "# =========================\n",
    "# Utilities (same as TF lab)\n",
    "# =========================\n",
    "\n",
    "def resize_to_fit(image, width, height):\n",
    "    h, w = image.shape\n",
    "    if w > h:\n",
    "        image = cv2.resize(image, (width, int(h * width / w)))\n",
    "    else:\n",
    "        image = cv2.resize(image, (int(w * height / h), height))\n",
    "\n",
    "    padW = (width - image.shape[1]) // 2\n",
    "    padH = (height - image.shape[0]) // 2\n",
    "\n",
    "    image = cv2.copyMakeBorder(\n",
    "        image, padH, padH, padW, padW,\n",
    "        cv2.BORDER_CONSTANT, value=255\n",
    "    )\n",
    "\n",
    "    return cv2.resize(image, (width, height))\n",
    "\n",
    "\n",
    "def group_every(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i + n]\n",
    "\n",
    "\n",
    "def make_feature(image):\n",
    "    image = resize_to_fit(image, 20, 20)\n",
    "    image = image[..., None]\n",
    "    return image\n",
    "\n",
    "\n",
    "def make_feature_label(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    feature = make_feature(image)\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "    return feature, label\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PyTorch CNN Model\n",
    "# =========================\n",
    "\n",
    "class CaptchaCNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(50 * 5 * 5, 500)\n",
    "        self.fc2 = nn.Linear(500, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load Character Dataset\n",
    "# =========================\n",
    "\n",
    "CHAR_IMAGE_FOLDER = \"./char-images-31528476\"\n",
    "LABELS_PATH = \"./labels.pkl\"\n",
    "\n",
    "image_paths = list(paths.list_images(CHAR_IMAGE_FOLDER))\n",
    "features, labels = zip(*(make_feature_label(p) for p in image_paths))\n",
    "\n",
    "X = np.array(features, dtype=\"float32\") / 255.0\n",
    "y = np.array(labels)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_onehot = lb.fit_transform(y)\n",
    "n_classes = len(lb.classes_)\n",
    "\n",
    "with open(LABELS_PATH, \"wb\") as f:\n",
    "    pickle.dump(lb, f)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_onehot, test_size=0.25, random_state=955996\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train).permute(0, 3, 1, 2)\n",
    "X_val   = torch.tensor(X_val).permute(0, 3, 1, 2)\n",
    "\n",
    "y_train = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long)\n",
    "y_val   = torch.tensor(np.argmax(y_val, axis=1), dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train, y_train),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(X_val, y_val),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Training\n",
    "# =========================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CaptchaCNN(n_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        train_correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    train_acc = train_correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            outputs = model(xb)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_correct += (preds == yb).sum().item()\n",
    "            val_total += yb.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{EPOCHS}] \"\n",
    "        f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Save Model\n",
    "# =========================\n",
    "\n",
    "MODEL_PATH = \"captcha_model_pytorch.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "print(\"Model saved to\", MODEL_PATH)\n"
   ],
   "id": "608a3d3daddf4ba7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Acc: 0.4499 | Val Acc: 0.8436\n",
      "Epoch [2/10] Train Acc: 0.9464 | Val Acc: 0.9542\n",
      "Epoch [3/10] Train Acc: 0.9784 | Val Acc: 0.9553\n",
      "Epoch [4/10] Train Acc: 0.9896 | Val Acc: 0.9743\n",
      "Epoch [5/10] Train Acc: 0.9963 | Val Acc: 0.9765\n",
      "Epoch [6/10] Train Acc: 0.9944 | Val Acc: 0.9765\n",
      "Epoch [7/10] Train Acc: 0.9985 | Val Acc: 0.9821\n",
      "Epoch [8/10] Train Acc: 1.0000 | Val Acc: 0.9821\n",
      "Epoch [9/10] Train Acc: 1.0000 | Val Acc: 0.9821\n",
      "Epoch [10/10] Train Acc: 1.0000 | Val Acc: 0.9821\n",
      "Model saved to captcha_model_pytorch.pth\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
